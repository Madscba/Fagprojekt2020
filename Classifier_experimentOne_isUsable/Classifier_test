import numpy as np
import pandas as pd
from sklearn import model_selection
from Preprossering.PreprosseringPipeline import preprossingPipeline
from Classifier_experimentOne_isUsable.trainTestValidateClassifiers import getClassifierAccuracies,tryNewDiv
import random
import os
import json

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

class classifier_validation():
    def __init__(self,Bc_path,feture_path,speck_path,Kfold_path=r"Preprossering//K-fold.json",max_files=None,logfile_path=None):
        self.max_files=max_files
        self.logfile_path=logfile_path

        self.prepros = preprossingPipeline(mac=False, BC_datapath=Bc_path)
        self.feture_path=feture_path
        self.speck_path=speck_path

        with open(os.path.join(os.getcwd(),Kfold_path) , "r") as read_file:
            self.Kfold = json.load(read_file)

    def get_spectrogram(self,x):
        spectrograms, spectrogram_labels, _, _ = self.prepros.make_label(make_from_filenames=x, quality=None,
                                                                        is_usable=None, max_files=self.max_files,
                                                                        path=self.speck_path)  # 18 files = 1926
        feature_vectors_labels=[self.prepros.edfDict[lable]["annotation"]["Is Eeg Usable For Clinical Purposes"] for lable in spectrogram_labels]

        return spectrograms,spectrogram_labels

    def get_feturevectors(self,x):
        feature_vectors, feature_vectors_labels, _, _ = self.prepros.make_label(make_from_filenames=x,
                                                                                 quality=None, is_usable=None,
                                                                                 max_files=self.max_files,
                                                                                 path=self.feture_path)  # 18 files = 2144
        feature_vectors_labels=[self.prepros.edfDict[lable]["annotation"]["Is Eeg Usable For Clinical Purposes"] for lable in feature_vectors_labels]
        return feature_vectors, feature_vectors_labels


    def test(self,type,folds=None,classifyers=["SVM", "LDA", "DecisionTree", "RF"],logname="test.json"):
        """
        :param x:
        :param y:
        :return pandas df for feture vectors and spectrograms:
        """

        if isinstance(folds, dict):
            folddic=folds
        else:
            folddic=self.Kfold

            if folds!=None:
                for i in folds:
                    try:
                        folddic=folddic[f"subfolds_{i}"]
                    except:
                        print(f"Invalid fold index {i} max fold is {folddic['N_folds']}")

        Nfold=folddic['N_folds']
        AC_collumns=np.append(classifyers,["N_TestFiles","N_TestWindows","N_TrainFiles","N_TrainWindows"])
        AC_matrix = pd.DataFrame(index=np.arange(0, Nfold), columns=AC_collumns)
        for n in range(Nfold):
            trainNames=folddic[f"train_{n}"]
            testNames=folddic[f"test_{n}"]

            if type=="fetures":
                #Test feturevectors
                x_train,y_train=self.get_feturevectors(trainNames)
                x_test, y_test = self.get_feturevectors(testNames)

            elif type=="spectrograms":
                #Test spectrograms
                x_train,y_train=self.get_spectrogram(trainNames)
                x_test, y_test = self.get_spectrogram(testNames)
            else:
                raise Exeption("wrong type try fetures or spectrograms")

            for C in classifyers:
                if C=="SVM":
                    AC_matrix.loc[n,C]=self.predict_svm(x_train,y_train,x_test,y_test)

                if C=="LDA":
                    AC_matrix.loc[n,C]=self.predict_LDA(x_train,y_train,x_test,y_test)

                if C=="GNB":
                    AC_matrix.loc[n,C]=self.predict_GNF(x_train,y_train,x_test,y_test)

                if C=="DecisionTree":
                    AC_matrix.loc[n,C]=self.predict_DissionTree(x_train,y_train,x_test,y_test)

                if C=="RF":
                    AC_matrix.loc[n, C] = self.predict_RF(x_train, y_train, x_test, y_test)

                AC_matrix.loc[n,"N_TestFiles"]=len(testNames)
                AC_matrix.loc[n, "N_TestWindows"] = len(x_test)
                AC_matrix.loc[n, "N_TrainFiles"] = len(trainNames)
                AC_matrix.loc[n, "N_TrainWindows"] = len(x_train)

            print(f"fold {n} completet")
            #print(AC_matrix)
        if logname is not None:
            AC_matrix.to_csv(os.path.join(os.getcwd(), os.path.join(os.getcwd(),self.logfile_path,logname)))
        return  AC_matrix

    def two_layes(self,type,classifyers=["SVM", "LDA", "DecisionTree", "RF"]):
        """
        Implement two layers cross validation as spesified in 02450book algoritme 6 page 175
        :param type:
        :return:
        """
        folddic = self.Kfold

        for n in range(folddic['N_folds']):

            Innerresult=self.test(folds=[n], type=type, logname=None)
            totalDatapoint=Innerresult.loc["N_TestWindows"].sum()

            Egen_s=[np.sum([(Innerresult.loc["N_TestWindows"].iloc[j]/totalDatapoint)*Innerresult.loc[s].iloc[j]
                            for j in range(len(Innerresult.index))]) for s in Innerresult.columns()]



        #Feture_AC_matrix = pd.DataFrame(Feture_AC_matrix,columns=["svm_predict", "LDA_predict", "DecisionTree_predict", "RF_predict"])
        #Spec_AC_matrix = pd.DataFrame(Spec_AC_matrix,columns=["svm_predict", "LDA_predict", "DecisionTree_predict", "RF_predict"])
        #return Feture_AC_matrix, Spec_AC_matrix

    def predict_LDA(self,x,y,x_test,y_test):
        LDA_predict = np.array([])
        LDA = LinearDiscriminantAnalysis()
        LDA.fit(x, y)
        LDA_predict = np.append(LDA_predict, LDA.predict(x_test))
        print("Lda done", np.mean(y_test == LDA_predict))
        return np.mean(y_test == LDA_predict)

    def predict_svm(self,x,y,x_test,y_test):
        svm_predict = np.array([])
        # support vector machine
        m_svm = SVC(gamma="auto", kernel="linear")
        m_svm.fit(x, y)
        svm_predict = np.append(svm_predict, m_svm.predict(x_test))
        print("SVM done", np.mean(y_test == svm_predict))

        return np.mean(y_test == svm_predict)

    def predict_GNB(self,x,y,x_test,y_test):
        GNB_predict = np.array([])
        m_gaus = GaussianNB()
        m_gaus.fit(x_train, y_train)
        GNB_predict = np.append(GNB_predict, m_gaus.predict(x_test))
        print("gaus done", np.mean(y_test == GNB_predict))
        return  np.mean(y_test == GNB_predict)


    def predict_DissionTree(self,x_train,y_train,x_test,y_test):
        DecisionTree_predict =np.array([])
        m_DecisionTree = DecisionTreeClassifier()
        m_DecisionTree.fit(x_train, y_train)
        DecisionTree_predict = np.append(DecisionTree_predict, m_DecisionTree.predict(x_test))
        print("DT done", np.mean(y_test == DecisionTree_predict))
        return np.mean(y_test == DecisionTree_predict)

    def predict_RF(self,x_train,y_train,x_test,y_test):
        RF_predict = np.array([])

        ranFor = RandomForestClassifier(n_estimators=100, criterion='gini')
        ranFor.fit(x_train, y_train)
        RF_predict = np.append(RF_predict, ranFor.predict(x_test))
        print("RF done", np.mean(y_test == RF_predict))
        return np.mean(y_test == RF_predict)

    def predict_clf(self,x,y,x_test,y_test):
        pass
        #TODO denne function var ikke skævet færdigt.
    # clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 20, 20, 10), random_state=1)
    # clf.fit(x_train, y_train)
    # clf_predict = np.append(clf_predict, clf.predict(x_test))
    # print("neural done",np.mean(y_true == clf_predict))
if __name__ == '__main__':
    CV=classifier_validation(Bc_path=r"C:\Users\Andre\Desktop\Fagproject\Data\BC",feture_path=r'C:\Users\Andre\Desktop\Fagproject\feature_vectors',speck_path=r'C:\Users\Andre\Desktop\Fagproject\Spektrograms',logfile_path="ClassifierTestLogs",max_files=4)
    #CV.test(folds=None, type="fetures", logname="OuterloopFeturer.json")
    CV.test(folds=None,type="spectrograms",logname="OuterloopSpectrograms.json")
    CV.two_layes(type="fetures")